import sys, os, glob,subprocess,re


#this function is used to create a folder to keep the output of each tool
def createFolder(local_dir):
    sbatch_dir = os.path.join(local_dir, "sbatch")
    out_dir    = os.path.join(local_dir, "sbatch_out")
    err_dir    = os.path.join(local_dir, "sbatch_err")

    if not os.path.isdir(sbatch_dir):
        os.makedirs(sbatch_dir)
    if not os.path.isdir(out_dir):
        os.makedirs(out_dir)
    if not os.path.isdir(err_dir):
        os.makedirs(err_dir)
    return(sbatch_dir,out_dir,err_dir);
#this function submits the slurmjob generated by one of the tool scripts
def generateSlurmJob(sbatch_dir,sample_name):
    process = "sbatch {0}".format(os.path.join(sbatch_dir, "{0}.slurm").format(sample_name))
    p_handle = subprocess.Popen(process, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)    
    p_out, p_err = p_handle.communicate()
    try:
        return( re.match(r'Submitted batch job (\d+)', p_out).groups()[0] );
    except AttributeError:
        raise RuntimeError('Could not submit sbatch')


#module used to filter the cariant call files
def runScripts(analysisTool,tool,analysedProject,analysed,programDirectory,account):
        VCFinput="";
        VCFinterinput="";
        VCFintrainput="";
  
        add2Ongoing={};


        #create a text string containing the path to each vcf separated by blanks
        for sample in analysedProject:
                path=analysed[analysisTool][sample]["outpath"];
                if analysisTool == "CNVnator":
                        VCFfile=sample+".cnvnator.vcf"
                        VCFinput += " " + os.path.join(path,analysisTool,VCFfile );
                        fileDict={"CNVnator":VCFinput}
                        
                elif (analysisTool == "FindTranslocations"):
                        VCFintra=sample+"_intra_chr_events.vcf"
                        VCFinter=sample+"_inter_chr_events.vcf"
                        VCFinterinput+=" " + os.path.join(path,analysisTool,VCFinter );
                        VCFintrainput+=" " + os.path.join(path,analysisTool,VCFintra );
                        fileDict={"intra_DB":VCFintrainput,"inter_DB":VCFinterinput}

        #construct database
        if(analysisTool == "FindTranslocations" or analysisTool == "CNVnator"):       
                pid=build_db(programDirectory, os.path.join(path,analysisTool,"filtered") , analysed[analysisTool][sample]["project"] , fileDict ,account,analysisTool)
                #update the add2ongoing dictionary
                for sample in analysedProject:
                        add2Ongoing.update({sample:{"pid":pid,"outpath":analysed[analysisTool][sample]["outpath"],"project":analysed[analysisTool][sample]["project"]}});
	return add2Ongoing;

def build_db(programDirectory, outpath , project , fileDict ,account,analysisTool):
    #path to the folder were the reference chromosomes are stored
    sbatch_dir,out_dir,err_dir=createFolder(outpath);

    path2Build = os.path.join(programDirectory,"programFiles","FindTranslocations","scipts","build_db.py")
    path2Query = os.path.join(programDirectory,"programFiles","FindTranslocations","scipts","query_db.py")
    with open(os.path.join(sbatch_dir, "{0}.slurm".format(project)), 'w') as sbatch:
		
        sbatch.write("#! /bin/bash -l\n")
        sbatch.write("#SBATCH -A {}\n".format(account))
        sbatch.write("#SBATCH -o {0}/buildDB_{1}.out\n".format(out_dir,project))
        sbatch.write("#SBATCH -e {0}/buildDB_{1}.err\n".format(err_dir,project))
        sbatch.write("#SBATCH -J buildDB_{0}_{1}.job\n".format(project,analysisTool))
        sbatch.write("#SBATCH -p core\n")
        sbatch.write("#SBATCH -t 5:00:00\n")
        sbatch.write("#SBATCH -n 1 \n")
        sbatch.write("\n")
        sbatch.write("\n")
        #create a database for each kind of vcf file
        for files in fileDict:
                print(fileDict[files]);
                DBPath=os.path.join(outpath,"{0}_{1}.db".format(project,files))
                sbatch.write("python {0} --variations {1} > {2}\n".format(path2Build,fileDict[files],DBPath) );
                #after the database is generated, query against it
                sbatch.write("\n");
                samples=fileDict[files].split();
                print(samples)
                print(fileDict[files]);

                for sample in samples:
                        print("{0}_Query.vcf".format(sample.split(".")[0]));

                        filename=sample.split(".")[0].rsplit("/")[-1]
                        filePath=os.path.join(outpath,"{0}_Query.vcf".format(filename))
                        sbatch.write("python {0} --variations {1} --db {2} > {3}\n".format(path2Query,sample ,DBPath,filePath) );
        sbatch.write("\n")
        sbatch.write("\n")

    return ( int(generateSlurmJob(sbatch_dir,project)) );

